{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92778525",
   "metadata": {},
   "source": [
    "# Assignment 4: Pipelines and Hyperparameter Tuning (32 total marks)\n",
    "### Due: November 22 at 11:59pm\n",
    "\n",
    "### Name: Nick Nikolov"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce31b39a",
   "metadata": {},
   "source": [
    "### In this assignment, you will be putting together everything you have learned so far. You will need to find your own dataset, do all the appropriate preprocessing, test different supervised learning models and evaluate the results. More details for each step can be found below.\n",
    "\n",
    "### You will also be asked to describe the process by which you came up with the code. More details can be found below. Please cite any websites or AI tools that you used to help you with this assignment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf275ca7",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "2b67a661",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8219f163",
   "metadata": {},
   "source": [
    "## Step 1: Data Input (4 marks)\n",
    "\n",
    "Import the dataset you will be using. You can download the dataset onto your computer and read it in using pandas, or download it directly from the website. Answer the questions below about the dataset you selected. \n",
    "\n",
    "To find a dataset, you can use the resources listed in the notes. The dataset can be numerical, categorical, text-based or mixed. If you want help finding a particular dataset related to your interests, please email the instructor.\n",
    "\n",
    "**You cannot use a dataset that was used for a previous assignment or in class**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "2af8bd32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method NDFrame.head of      Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
      "0              6      148             72             35        0  33.6   \n",
      "1              1       85             66             29        0  26.6   \n",
      "2              8      183             64              0        0  23.3   \n",
      "3              1       89             66             23       94  28.1   \n",
      "4              0      137             40             35      168  43.1   \n",
      "..           ...      ...            ...            ...      ...   ...   \n",
      "763           10      101             76             48      180  32.9   \n",
      "764            2      122             70             27        0  36.8   \n",
      "765            5      121             72             23      112  26.2   \n",
      "766            1      126             60              0        0  30.1   \n",
      "767            1       93             70             31        0  30.4   \n",
      "\n",
      "     DiabetesPedigreeFunction  Age  \n",
      "0                       0.627   50  \n",
      "1                       0.351   31  \n",
      "2                       0.672   32  \n",
      "3                       0.167   21  \n",
      "4                       2.288   33  \n",
      "..                        ...  ...  \n",
      "763                     0.171   63  \n",
      "764                     0.340   27  \n",
      "765                     0.245   30  \n",
      "766                     0.349   47  \n",
      "767                     0.315   23  \n",
      "\n",
      "[768 rows x 8 columns]>\n",
      "(768, 8)\n",
      "(768,)\n"
     ]
    }
   ],
   "source": [
    "# Import dataset (1 mark)\n",
    "df = pd.read_csv(\"diabetes.csv\")\n",
    "\n",
    "#Split into target and feature vectors\n",
    "y = df.pop('Outcome')\n",
    "\n",
    "print(df.head)\n",
    "print(df.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20316765",
   "metadata": {},
   "source": [
    "### Questions (3 marks)\n",
    "\n",
    "1. (1 mark) What is the source of your dataset? From Kaggle: https://www.kaggle.com/datasets/pentakrishnakishore/diabetes-csv?select=diabetes.csv \n",
    "\n",
    "1. (1 mark) Why did you pick this particular dataset? Often I find I'm interested in medical data, maybe because of the complexity of the human system. Seems very difficult to predict outcomes in humans.\n",
    "\n",
    "1. (1 mark) Was there anything challenging about finding a dataset that you wanted to use? Kaggle had a few interesting sets. I almost used a luxury watch price dataset but I couldn't think of anything interesting to predict with that set. Diabetes seemed to be a useful prediction.\n",
    "\n",
    "*ANSWER HERE*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42fea4cc",
   "metadata": {},
   "source": [
    "## Step 2: Data Processing (5 marks)\n",
    "\n",
    "The next step is to process your data. Implement the following steps as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "afc244d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pregnancies                 0\n",
      "Glucose                     0\n",
      "BloodPressure               0\n",
      "SkinThickness               0\n",
      "Insulin                     0\n",
      "BMI                         0\n",
      "DiabetesPedigreeFunction    0\n",
      "Age                         0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Clean data (if needed)\n",
    "#Check for any Null values\n",
    "\n",
    "nulls = df.isnull().sum().sort_values(ascending=False)\n",
    "print(nulls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "70a8c127",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement preprocessing steps. Remember to use ColumnTransformer if more than one preprocessing method is needed\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(df, y, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b92c46b7",
   "metadata": {},
   "source": [
    "### Questions (2 marks)\n",
    "\n",
    "1. (1 mark) Were there any missing/null values in your dataset? If yes, how did you replace them and why? If no, describe how you would've replaced them and why. \n",
    "\n",
    "There were no missing values in this dataset. Since I'm not sure which feature might be the most important in predicting diabetes, I would drop the row if there was a missing value. For example, I think glucose is a very important indicator of diabetes, so if a glucose measurement was missing it would have a big effect on the results. We also can't replace it with zero since a zero glucose measurement is also medically important (impossible?). This applies to many other features, BMI, blood pressure, Age etc, cannot be filled with an average value or filled with zeros. Therefore dropping the value is most appropriate.\n",
    "\n",
    "2. (1 mark) What type of data do you have? What preprocessing methods would you have to apply based on your data types? \n",
    "\n",
    "The diabetes dataset is used to classify a patient as either having diabetes or not having diabetes. This is a categorical dataset. Have to apply scaling since most non-linear models require scaling. Since all of the data is numerical, encoding is not required.\n",
    "\n",
    "*ANSWER HERE*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a245d00",
   "metadata": {},
   "source": [
    "## Step 3: Implement Machine Learning Model (11 marks)\n",
    "\n",
    "In this section, you will implement three different supervised learning models (one linear and two non-linear) of your choice. You will use a pipeline to help you decide which model and hyperparameters work best. It is up to you to select what models to use and what hyperparameters to test. You can use the class examples for guidance. You must print out the best model parameters and results after the grid search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "5558a776",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement pipeline and grid search here. Can add more code blocks if necessary\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#placeholders for now\n",
    "pipe = Pipeline(steps=[('preprocessing', StandardScaler()), ('classifier', LogisticRegression(max_iter=10))])\n",
    "\n",
    "param_grid = [{'classifier': [SVC()], \n",
    "               'classifier__C': [0.01, 0.1, 1.0, 10.0],\n",
    "               'preprocessing': [StandardScaler(), None]\n",
    "              },\n",
    "              {'classifier': [RandomForestClassifier(random_state=0)], \n",
    "               'classifier__max_depth': [1, 3, 5, 7],\n",
    "               'preprocessing': [None]\n",
    "              }, \n",
    "             {'classifier': [LogisticRegression(max_iter=1000)], \n",
    "              'classifier__C': [1, 10, 100, 1000], \n",
    "              'preprocessing': [None]\n",
    "             }]\n",
    "\n",
    "grid = GridSearchCV(pipe, param_grid, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "a6a86617-2315-4844-b20e-fdc82df818e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-24 {color: black;}#sk-container-id-24 pre{padding: 0;}#sk-container-id-24 div.sk-toggleable {background-color: white;}#sk-container-id-24 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-24 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-24 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-24 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-24 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-24 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-24 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-24 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-24 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-24 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-24 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-24 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-24 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-24 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-24 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-24 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-24 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-24 div.sk-item {position: relative;z-index: 1;}#sk-container-id-24 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-24 div.sk-item::before, #sk-container-id-24 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-24 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-24 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-24 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-24 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-24 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-24 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-24 div.sk-label-container {text-align: center;}#sk-container-id-24 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-24 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-24\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[(&#x27;preprocessing&#x27;, StandardScaler()),\n",
       "                                       (&#x27;classifier&#x27;,\n",
       "                                        LogisticRegression(max_iter=10))]),\n",
       "             param_grid=[{&#x27;classifier&#x27;: [SVC()],\n",
       "                          &#x27;classifier__C&#x27;: [0.01, 0.1, 1.0, 10.0],\n",
       "                          &#x27;preprocessing&#x27;: [StandardScaler(), None]},\n",
       "                         {&#x27;classifier&#x27;: [RandomForestClassifier(random_state=0)],\n",
       "                          &#x27;classifier__max_depth&#x27;: [1, 3, 5, 7],\n",
       "                          &#x27;preprocessing&#x27;: [None]},\n",
       "                         {&#x27;classifier&#x27;: [LogisticRegression(C=10,\n",
       "                                                            max_iter=1000)],\n",
       "                          &#x27;classifier__C&#x27;: [1, 10, 100, 1000],\n",
       "                          &#x27;preprocessing&#x27;: [None]}])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-72\" type=\"checkbox\" ><label for=\"sk-estimator-id-72\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[(&#x27;preprocessing&#x27;, StandardScaler()),\n",
       "                                       (&#x27;classifier&#x27;,\n",
       "                                        LogisticRegression(max_iter=10))]),\n",
       "             param_grid=[{&#x27;classifier&#x27;: [SVC()],\n",
       "                          &#x27;classifier__C&#x27;: [0.01, 0.1, 1.0, 10.0],\n",
       "                          &#x27;preprocessing&#x27;: [StandardScaler(), None]},\n",
       "                         {&#x27;classifier&#x27;: [RandomForestClassifier(random_state=0)],\n",
       "                          &#x27;classifier__max_depth&#x27;: [1, 3, 5, 7],\n",
       "                          &#x27;preprocessing&#x27;: [None]},\n",
       "                         {&#x27;classifier&#x27;: [LogisticRegression(C=10,\n",
       "                                                            max_iter=1000)],\n",
       "                          &#x27;classifier__C&#x27;: [1, 10, 100, 1000],\n",
       "                          &#x27;preprocessing&#x27;: [None]}])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-73\" type=\"checkbox\" ><label for=\"sk-estimator-id-73\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;preprocessing&#x27;, StandardScaler()),\n",
       "                (&#x27;classifier&#x27;, LogisticRegression(max_iter=10))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-74\" type=\"checkbox\" ><label for=\"sk-estimator-id-74\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-75\" type=\"checkbox\" ><label for=\"sk-estimator-id-75\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=10)</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('preprocessing', StandardScaler()),\n",
       "                                       ('classifier',\n",
       "                                        LogisticRegression(max_iter=10))]),\n",
       "             param_grid=[{'classifier': [SVC()],\n",
       "                          'classifier__C': [0.01, 0.1, 1.0, 10.0],\n",
       "                          'preprocessing': [StandardScaler(), None]},\n",
       "                         {'classifier': [RandomForestClassifier(random_state=0)],\n",
       "                          'classifier__max_depth': [1, 3, 5, 7],\n",
       "                          'preprocessing': [None]},\n",
       "                         {'classifier': [LogisticRegression(C=10,\n",
       "                                                            max_iter=1000)],\n",
       "                          'classifier__C': [1, 10, 100, 1000],\n",
       "                          'preprocessing': [None]}])"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "92c365ec-ca44-4a9d-b057-bf1c9d313eb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-25 {color: black;}#sk-container-id-25 pre{padding: 0;}#sk-container-id-25 div.sk-toggleable {background-color: white;}#sk-container-id-25 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-25 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-25 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-25 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-25 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-25 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-25 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-25 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-25 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-25 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-25 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-25 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-25 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-25 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-25 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-25 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-25 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-25 div.sk-item {position: relative;z-index: 1;}#sk-container-id-25 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-25 div.sk-item::before, #sk-container-id-25 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-25 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-25 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-25 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-25 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-25 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-25 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-25 div.sk-label-container {text-align: center;}#sk-container-id-25 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-25 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-25\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;preprocessing&#x27;, None),\n",
       "                (&#x27;classifier&#x27;, LogisticRegression(C=10, max_iter=1000))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-76\" type=\"checkbox\" ><label for=\"sk-estimator-id-76\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;preprocessing&#x27;, None),\n",
       "                (&#x27;classifier&#x27;, LogisticRegression(C=10, max_iter=1000))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-77\" type=\"checkbox\" ><label for=\"sk-estimator-id-77\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">None</label><div class=\"sk-toggleable__content\"><pre>None</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-78\" type=\"checkbox\" ><label for=\"sk-estimator-id-78\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(C=10, max_iter=1000)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('preprocessing', None),\n",
       "                ('classifier', LogisticRegression(C=10, max_iter=1000))])"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "d0310b26-8abf-4263-b3dd-1abb38630d4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classifier': LogisticRegression(C=10, max_iter=1000),\n",
       " 'classifier__C': 10,\n",
       " 'preprocessing': None}"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "fbbf7413-bc17-4ecb-922a-07aa5746a93b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7638980509745128"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "16afa4f9-b94e-47a7-97ec-011f9fd5c122",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation accuracy 0.76\n",
      "Test accuracy 0.80\n"
     ]
    }
   ],
   "source": [
    "print(f'Cross-Validation accuracy {grid.best_score_:.2f}')\n",
    "print(f'Test accuracy {grid.score(X_test, y_test):.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dbd7075",
   "metadata": {},
   "source": [
    "### Questions (5 marks)\n",
    "\n",
    "1. (1 mark) Do you need regression or classification models for your dataset? \n",
    "\n",
    "My dataset uses classification, either the patient has diabetes or they do not. There is no range of values in the target vector.\n",
    "\n",
    "1. (2 marks) Which models did you select for testing and why? \n",
    "\n",
    "I selected logisticRegression, RandomForrests, and SVC. Logisticregression is used since in high dimensional data linear models may perform better than non-linear models (RandomForrests). Random forrests were chosen since they typically perform very well. SVC is chosen as another non-linear model that works differently than RandomForrests.\n",
    "\n",
    "1. (2 marks) Which model worked the best? Does this make sense based on the theory discussed in the course and the context of your dataset? \n",
    "\n",
    "The Logistic regression model performed the best. I thought the randomforrest would perform the best since randomForrests typically perform very well. From the notes, weaknesses of randomforrests are explained to be in high dimensional sparse data. However this dataset only has 8 features so randomforrests should perform well. Maybe the features selected simply don't predict diabetes well. \n",
    "\n",
    "If the data was high dimensional then the logistic regression model would be predicted to perform better than random Forrests. \n",
    "\n",
    "*ANSWER HERE*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f994e31",
   "metadata": {},
   "source": [
    "## Step 4: Validate Model (6 marks)\n",
    "\n",
    "Use the testing set to calculate the testing accuracy for the best model determined in Step 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "69e64c08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall Score 0.58\n"
     ]
    }
   ],
   "source": [
    "# Calculate testing accuracy (1 mark)\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "pipe = Pipeline(steps=[('preprocessing', StandardScaler()), ('classifier', LogisticRegression(C=10, max_iter=1000))])\n",
    "\n",
    "pipe.fit(X_train, y_train)\n",
    "y_pred = pipe.predict(X_test)\n",
    "print(f'Recall Score {recall_score(y_test, y_pred):.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e4529ba",
   "metadata": {},
   "source": [
    "\n",
    "### Questions (5 marks)\n",
    "\n",
    "1. (1 mark) Which accuracy metric did you choose? \n",
    "\n",
    "Recall, since we want to maximize all of the true positive detections.\n",
    "\n",
    "1. (1 mark) How do these results compare to those in part 3? Did this model generalize well? \n",
    "\n",
    "This model performed very poorly with a Recall of only 0.58.\n",
    "\n",
    "1. (3 marks) Based on your results and the context of your dataset, did the best model perform \"well enough\" to be used out in the real-world? Why or why not? Do you have any suggestions for how you could improve this analysis?\n",
    "\n",
    "Definitely not. The best model was determined to be a logisticRegression with C=10. However, the calculated recall only scored 0.58. In a real-world setting we would be making a ton of false predictions on patients. Since these decisions could have a lifelong impact on patients, it would be immoral to apply this particular model in the real-world given the poor accuracy. Personally, I would be happy with >80% diagnoses accuracy from my doctor, so I would expect at least that score from this prediction model. \n",
    "\n",
    "I spent a lot of time trying other types of models with a different range of parameters but still the logisticregression model with a recall score of 0.58 was the best I could find. Not sure why it's performing so poorly. Maybe the features selection in the dataset simply don't predict diabetes very well. \n",
    "\n",
    "*ANSWER HERE*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37b238f4",
   "metadata": {},
   "source": [
    "## Process Description (4 marks)\n",
    "Please describe the process you used to create your code. Cite any websites or generative AI tools used. You can use the following questions as guidance:\n",
    "1. Where did you source your code? Lecture Slides, Tutorials (Scaling.ipynb, PipelineSteps.ipynb, Pipeline.ipynb, ApplyPipelines.ipynb), sci-kit learn documentation (https://scikit-learn.org/stable/modules/grid_search.html), https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html\n",
    "\n",
    "1. In what order did you complete the steps? Numerical order. \n",
    "\n",
    "1. If you used generative AI, what prompts did you use? Did you need to modify the code at all? Why or why not? \n",
    "\n",
    "I used ChatGPT for a few code syntax questions (how do I remove one column from a pandas dataframe). Saved me time from searching through stackoverflow or the pandas documentation. I know for simple syntax questions ChatGPT is very good.\n",
    "\n",
    "1. Did you have any challenges? If yes, what were they? If not, what helped you to be successful?\n",
    "\n",
    "It took me a while to figure out the correct syntax for the parameter grid. Spent a lot of time trying to figure out why my models were performing so poorly and kept trying different inputs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93097bfe",
   "metadata": {},
   "source": [
    "*DESCRIBE YOUR PROCESS HERE*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd97b6ac",
   "metadata": {},
   "source": [
    "## Reflection (2 marks)\n",
    "Include a sentence or two about:\n",
    "- what you liked or disliked,\n",
    "- found interesting, confusing, challenging, motivating\n",
    "while working on this assignment.\n",
    "\n",
    "It was fun searching through Kaggle to see what datasets I might find interesting. Also asking friends for dataset ideas and what they think machine learning is capable of doing. \n",
    "\n",
    "*ADD YOUR THOUGHTS HERE*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
